{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOYufp6vm3VJB8/hINQoTkn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlosramos1/practicas-machine-learning/blob/main/TF_IDF_(implementacion).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import log"
      ],
      "metadata": {
        "id": "Sm1qqcDnAFTc"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tf-IDF\n",
        "\n",
        "Determina la importancia de un token (palabra)\n",
        "\n",
        "TFIDF es la multiplicación de dos expresiones:\n",
        "\n",
        "$$\n",
        "tf\\,idf(w,d,D) = tf(w,d) * idf(w,D)\n",
        "$$\n",
        "\n",
        "- $tf(w,d)$ es la frecuencia de aparición de una palabra en un documento.\n",
        "- $idf(w,D)$ es la proporción inversa de documentos, indica si una palabra es común en el corpus."
      ],
      "metadata": {
        "id": "tp_LsX4R-nMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_tfidf(word, doc, corpus):\n",
        "  return calc_tf(word, doc) * calc_idf(word, corpus)"
      ],
      "metadata": {
        "id": "3XTeb5EaH8Ne"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cálculo de** $tf$\n",
        "$$\n",
        "tf(w,d) = f_{w,d}\n",
        "$$\n",
        "\n",
        "- Básicamente es hacer un conteo de las ocurrencias de la palabra $w$ en el documento $d$."
      ],
      "metadata": {
        "id": "wuVcBJp7zU--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_tf(word, doc):\n",
        "  return doc.count(word)"
      ],
      "metadata": {
        "id": "ybRg3zwB-q29"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cálculo de** $idf$\n",
        "\n",
        "$$\n",
        "idf(w,D) = log(|D| / df) + 1\n",
        "$$\n",
        "\n",
        "- $|D|$ es el total de documentos del corpus.\n",
        "- $df$ el número de documentos, donde el término $w$ está presente.\n",
        "- Añadimos $+1$ para evitar un resultado de cero.\n"
      ],
      "metadata": {
        "id": "9IatC9OH0BKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_idf(word, corpus):\n",
        "  N = len(corpus)\n",
        "  df = sum([word in doc for doc in corpus])\n",
        "  return round(log(N / df) + 1, 8)"
      ],
      "metadata": {
        "id": "pUoeVDI9-7Ac"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dado un vocabulario y un conjunto de documentos vamos a crear la matriz TF-IDF.\n",
        "\n",
        "Las filas representan los documentos y las columnas las pálabras.\n",
        "\n",
        "- vocabulario: una lista de palabras únicas.\n",
        "- documento: una lista de palabras.\n",
        "\n"
      ],
      "metadata": {
        "id": "h9N2Qi8i2LDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def matrix_tfidf(vocabulary, Docs):\n",
        "  N = len(Docs)\n",
        "  m = len(vocabulary)\n",
        "\n",
        "  # crear matriz de N filas, m columnas\n",
        "  tf_idf = [[0 for _ in range(m)] for _ in range(N)]\n",
        "\n",
        "  for w, word in enumerate(vocabulary):\n",
        "    for d, doc in enumerate(Docs):\n",
        "      tf_idf[d][w] = calc_tfidf(word, doc, Docs)\n",
        "  return tf_idf"
      ],
      "metadata": {
        "id": "aeDGeqPjTQh4"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo datos de juguete"
      ],
      "metadata": {
        "id": "I-tfHryNWWeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "          'This is the first document',\n",
        "          'This document is the second document',\n",
        "          'And this is the third one',\n",
        "          'Is this the first document',\n",
        "         ]\n",
        "corpus = [d.lower() for d in corpus]\n",
        "\n",
        "Docs = [d.split() for d in corpus]\n",
        "print(\"Documentos: \", Docs)\n",
        "\n",
        "vocabulary = list(set([w for doc in Docs for w in doc]))\n",
        "vocabulary.sort() # no es necesario, solo para comparar con sklearn\n",
        "print(\"Vocabulario: \", vocabulary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1P_uCJRfTqrj",
        "outputId": "7262d82e-7eff-4586-e6fe-db6ddc321bfe"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documentos:  [['this', 'is', 'the', 'first', 'document'], ['this', 'document', 'is', 'the', 'second', 'document'], ['and', 'this', 'is', 'the', 'third', 'one'], ['is', 'this', 'the', 'first', 'document']]\n",
            "Vocabulario:  ['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# obtener la matriz tfidf\n",
        "matrix_tfidf(vocabulary, Docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q7b-WNMaM4a",
        "outputId": "7c73c90b-cd38-4917-f796-0ae4c12ce5be"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.0, 1.28768207, 1.69314718, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0],\n",
              " [0.0, 2.57536414, 0.0, 1.0, 0.0, 2.38629436, 1.0, 0.0, 1.0],\n",
              " [2.38629436, 0.0, 0.0, 1.0, 2.38629436, 0.0, 1.0, 2.38629436, 1.0],\n",
              " [0.0, 1.28768207, 1.69314718, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorizar documentos nuevos dado el corpus\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wfh5rngDUD2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorized_tfidf(other_docs, vocabulary, Docs):\n",
        "  N = len(other_docs)\n",
        "  m = len(vocabulary)\n",
        "\n",
        "  # crear matriz de N filas, m columnas\n",
        "  tf_idf = [[0 for _ in range(m)] for _ in range(N)]\n",
        "\n",
        "  for w, word in enumerate(vocabulary):\n",
        "    for d, doc in enumerate(other_docs):\n",
        "      tf_idf[d][w] = calc_tfidf(word, doc, Docs)\n",
        "  return tf_idf"
      ],
      "metadata": {
        "id": "I9u5IMUoUOwq"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "other_doc = \"the new document\"\n",
        "vectorized_tfidf([other_doc.split()], vocabulary, Docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NmijVnTVJeb",
        "outputId": "bf0b64f2-e7b7-4b5f-f0da-6a95a964af81"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.0, 1.28768207, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparación con libreria `sklearn`"
      ],
      "metadata": {
        "id": "8l0Gh_lCWdy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(smooth_idf=False, norm=None)\n",
        "tfidf_vectorizer = vectorizer.fit_transform(corpus)\n",
        "vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cDO6-BGI4u2",
        "outputId": "2d8d00db-f37d-4c58-a4fd-9415a3a3a5b2"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n",
              "       'this'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odfXspc_3woG",
        "outputId": "1a1987f9-e6e2-4ce5-cdfc-df97d819a4ca"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 1.28768207, 1.69314718, 1.        , 0.        ,\n",
              "        0.        , 1.        , 0.        , 1.        ],\n",
              "       [0.        , 2.57536414, 0.        , 1.        , 0.        ,\n",
              "        2.38629436, 1.        , 0.        , 1.        ],\n",
              "       [2.38629436, 0.        , 0.        , 1.        , 2.38629436,\n",
              "        0.        , 1.        , 2.38629436, 1.        ],\n",
              "       [0.        , 1.28768207, 1.69314718, 1.        , 0.        ,\n",
              "        0.        , 1.        , 0.        , 1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.transform([other_doc]).toarray()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hquRtE1ZJk9-",
        "outputId": "4085d5c2-799f-44ed-84ed-e0c0cbd78828"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 1.28768207, 0.        , 0.        , 0.        ,\n",
              "        0.        , 1.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    }
  ]
}